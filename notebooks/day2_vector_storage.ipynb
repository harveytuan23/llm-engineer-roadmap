{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fca87d",
   "metadata": {},
   "source": [
    "進入 Day 2：Vector Storage。今天的目標是把「任意 PDF → 分割 → 向量化 → 建 FAISS 索引 → 檢索 → 串 Groq 產生回覆（RAG）」一次打通。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1344cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dotenv in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from faiss-cpu) (2.3.2)\n",
      "Requirement already satisfied: packaging in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (4.56.0)\n",
      "Requirement already satisfied: tqdm in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
      "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain-text-splitters)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading langsmith-0.4.21-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.11.7)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters)\n",
      "  Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: anyio in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-macosx_14_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.21-py3-none-any.whl (378 kB)\n",
      "Downloading orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl (127 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp313-cp313-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.1-cp313-cp313-macosx_14_0_arm64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: zstandard, threadpoolctl, tenacity, scipy, pypdf, orjson, jsonpointer, joblib, faiss-cpu, scikit-learn, requests-toolbelt, jsonpatch, langsmith, langchain-core, sentence-transformers, langchain-text-splitters\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [langchain-text-splitters]e-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed faiss-cpu-1.12.0 joblib-1.5.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.75 langchain-text-splitters-0.3.11 langsmith-0.4.21 orjson-3.11.3 pypdf-6.0.0 requests-toolbelt-1.0.0 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 tenacity-9.1.2 threadpoolctl-3.6.0 zstandard-0.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers pypdf langchain-text-splitters python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cb0698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # 讀 .env（請勿 commit）\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "assert GROQ_API_KEY, \"環境變數 GROQ_API_KEY 未設定。請先在 .env 或 os.environ 設定。\"\n",
    "\n",
    "from groq import Groq\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "420ec4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars: 23082\n",
      "Real-Time  Sign  Language  Detection  using  LSTM  \n",
      " Chung-Hao  Tuan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  tuanc@oregonstate.edu  \n",
      "Yun-Hsuan  Chan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  chanyun@oregonstate.edu  \n",
      "Fen-Yun  Huang  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  huanfeny@oregonstate.edu   \n",
      " \n",
      "Abstract\n",
      " \n",
      "    This  paper  proposes  a  real-time  sign  language  detection  system  utilizing  Long  Short-Term  Memory  (LSTM)  networks  combined  with  keypoint-based  feature  extraction.  The  system  leverages  MediaPipe  Holistic  for  extracting  skeletal  landmarks  from  hand,  face,  and  pose  keypoints.  Compared  to  conventional  approaches  like  Hidden  Markov  Models  (HMMs)  and  Convolutional  Neural  Networks  (CNNs),  LSTM  effectively  captures  temporal  dependencies  required  for  recognizing  continuous  gestures.  We  collected  1,500  gest\n"
     ]
    }
   ],
   "source": [
    "# 將你的 PDF 放到 repo 的 data/ 裡，例如 data/guide.pdf\n",
    "PDF_PATH = \"../data/Real-Time Sign Language Detection using LSTM.pdf\"  # ← 替換成你的檔名\n",
    "reader = PdfReader(PDF_PATH)\n",
    "\n",
    "pages = []\n",
    "for i, p in enumerate(reader.pages):\n",
    "    try:\n",
    "        pages.append(p.extract_text() or \"\")\n",
    "    except Exception as e:\n",
    "        pages.append(\"\")\n",
    "        \n",
    "raw_text = \"\\n\".join(pages).strip()\n",
    "print(\"Chars:\", len(raw_text))\n",
    "print(raw_text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba548e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 32\n",
      "Real-Time  Sign  Language  Detection  using  LSTM  \n",
      " Chung-Hao  Tuan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  tuanc@oregonstate.edu  \n",
      "Yun-Hsuan  Chan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  chanyun@oregonstate.edu  \n",
      "Fen\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # 可依文件長短調整（500~1200）\n",
    "    chunk_overlap=120,   # 避免斷句丟資訊\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"，\", \" \"]\n",
    ")\n",
    "chunks = splitter.split_text(raw_text)\n",
    "print(\"Chunks:\", len(chunks))\n",
    "print(chunks[0][:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf2a12",
   "metadata": {},
   "source": [
    "讓相似語意的句子向量靠近，無關的遠離\n",
    "每個段落 → 轉成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d28ad787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (32, 384) dim: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(embed_model_name)\n",
    "\n",
    "embeddings = embedder.encode(chunks, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "import numpy as np\n",
    "emb = np.array(embeddings).astype(\"float32\")\n",
    "dim = emb.shape[1]\n",
    "print(\"Embedding shape:\", emb.shape, \"dim:\", dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5c9097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed vectors: 32\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(dim)  # cosine 等效於 inner product + normalized vectors\n",
    "index.add(emb)                  # 加入全部 chunk 向量\n",
    "print(\"Indexed vectors:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06901875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " 'Real-Time  Sign  Language  Detection  using  LSTM  \\n Chung-Hao  Tuan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  tuanc@oregonstate.edu  \\nYun-Hsuan  Chan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  chanyun@oregonstate.edu  \\nFen')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query, k=5, mmr_lambda=0.5):\n",
    "    # 1) 將 query 向量化\n",
    "    qv = embedder.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    # 2) 先抓更多（例如 20）再做 MMR 去冗餘\n",
    "    fetch = max(k*4, 20)\n",
    "    D, I = index.search(qv, fetch)\n",
    "    cands = [(i, float(D[0][j])) for j, i in enumerate(I[0])]\n",
    "\n",
    "    # 3) 簡易 MMR\n",
    "    selected, selected_vecs = [], []\n",
    "    for idx, score in cands:\n",
    "        cv = emb[idx]\n",
    "        if not selected:\n",
    "            selected.append((idx, score))\n",
    "            selected_vecs.append(cv)\n",
    "            if len(selected) >= k: break\n",
    "            continue\n",
    "        # 與已選的最大相似度\n",
    "        sim_to_S = max(float(np.dot(cv, sv)) for sv in selected_vecs)\n",
    "        mmr = mmr_lambda*score - (1-mmr_lambda)*sim_to_S\n",
    "        # 用門檻挑（簡易版）；更嚴謹可逐步 argmax\n",
    "        if mmr > -0.2 or len(selected)<k:\n",
    "            selected.append((idx, score))\n",
    "            selected_vecs.append(cv)\n",
    "            if len(selected) >= k: break\n",
    "    return [chunks[i] for i,_ in selected]  #最後把挑到的 k 個段落（文字本體）回傳\n",
    "\n",
    "# quick test\n",
    "query = \"這份文件的重點與使用步驟是什麼？\"\n",
    "ctx = search(query, k=5)\n",
    "len(ctx), ctx[0][:300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5f2aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper leverages MediaPipe Holistic to extract a comprehensive set of keypoints, including:\n",
      "\n",
      "1. Pose landmarks (33 landmarks, 132 dimensional features)\n",
      "2. Facial landmarks (468 landmarks, 1,404 dimensional features)\n",
      "3. Hand landmarks (21 landmarks per hand, 126 dimensional features)\n"
     ]
    }
   ],
   "source": [
    "def rag_answer(question, k=5, sys_prompt=\"You are a precise assistant. Use the context to answer concisely. If unknown, say you don't know.\"):\n",
    "    context = \"\\n\\n\".join(search(question, k=k))\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\": sys_prompt},\n",
    "        {\"role\":\"user\",\"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer in English.\"}\n",
    "    ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "print(rag_answer(\"How does the paper do Keypoint Extraction?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06375952",
   "metadata": {},
   "source": [
    "Q: 都搜尋到了為什麼還要丟給groq回答\n",
    "\n",
    "A: 檢索 = 圖書館員幫你找到 3 本相關的書，翻到標記好的頁面。\n",
    "\n",
    "生成 (Groq LLM) = 一個研究助理幫你讀這些頁面，濃縮出「這篇 paper 用 SIFT 做 keypoint extraction」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8e732d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the paper do Keypoint Extraction?',\n",
       " 'answer': 'The paper leverages MediaPipe Holistic to extract a comprehensive set of keypoints, including:\\n\\n1. Pose landmarks (33 landmarks, 132 dimensional features)\\n2. Facial landmarks (468 landmarks, 1,404 dimensional features)\\n3. Hand landmarks (21 landmarks per hand, 126 dimensional features)\\n\\nThese keypoints are used for gesture recognition.',\n",
       " 'sources': [{'idx': 0,\n",
       "   'snippet': 'performance  across  different  ambient  lighting  conditions.  ●  Camera  setup:  Standard  webcam  hardware  was  used  in  conjunction  with  OpenCV  for  video  capture  and  MediaPipe  Holistic  for  keypoint  detection,  reflecting  typical  end-user  hardware  configurations.  This  approach '},\n",
       "  {'idx': 1,\n",
       "   'snippet': 'We  leveraged  MediaPipe  Holistic  to  extract  a  comprehensive  set  of  keypoints:  \\n●  Pose  landmarks:  A  set  of  33  landmarks  representing  the  human  skeleton,  each  characterized  by  spatial  coordinates  (x,  y,  z)  and  a  visibility  attribute,  yielding  132  dimensional  featur'},\n",
       "  {'idx': 2,\n",
       "   'snippet': '3.3.2  Time  Shifting  \\n  We  shift  the  entire  gesture  sequence  by  different  numbers  of  frames  (+1,  +2,  -1,  and  +3  frames)  to  account  for  temporal  variations  in  gesture  execution,  enabling  the  model  to  recognize  core  patterns  regardless  of  start-up  time  or  executi'},\n",
       "  {'idx': 3,\n",
       "   'snippet': 'This  research  proposes  an  approach  to  detect  sign  language  using  LSTM  and  extracts  hand,  face  and  pose  key  points  using  video  frames  with  MediaPipe  Holistic.  The  model  accurately  recognizes  gestures  and  retains  the  order  of  movements  as  sequences  with  the  help'}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rag_with_sources(question, k=5):\n",
    "    retrieved = search(question, k=k)\n",
    "    answer = rag_answer(question, k=k)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [{\"idx\": i, \"snippet\": s[:300]} for i, s in enumerate(retrieved)]\n",
    "    }\n",
    "\n",
    "res = rag_with_sources(\"How does the paper do Keypoint Extraction?\", k=4)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f4744",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
