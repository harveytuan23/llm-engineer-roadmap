{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ce466f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # 讀 .env（請勿 commit）\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "assert GROQ_API_KEY, \"環境變數 GROQ_API_KEY 未設定。請先在 .env 或 os.environ 設定。\"\n",
    "\n",
    "from groq import Groq\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f415cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars: 23082\n",
      "Real-Time  Sign  Language  Detection  using  LSTM  \n",
      " Chung-Hao  Tuan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  tuanc@oregonstate.edu  \n",
      "Yun-Hsuan  Chan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  chanyun@oregonstate.edu  \n",
      "Fen-Yun  Huang  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  huanfeny@oregonstate.edu   \n",
      " \n",
      "Abstract\n",
      " \n",
      "    This  paper  proposes  a  real-time  sign  language  detection  system  utilizing  Long  Short-Term  Memory  (LSTM)  networks  combined  with  keypoint-based  feature  extraction.  The  system  leverages  MediaPipe  Holistic  for  extracting  skeletal  landmarks  from  hand,  face,  and  pose  keypoints.  Compared  to  conventional  approaches  like  Hidden  Markov  Models  (HMMs)  and  Convolutional  Neural  Networks  (CNNs),  LSTM  effectively  captures  temporal  dependencies  required  for  recognizing  continuous  gestures.  We  collected  1,500  gest\n"
     ]
    }
   ],
   "source": [
    "# 將你的 PDF 放到 repo 的 data/ 裡，例如 data/guide.pdf\n",
    "PDF_PATH = \"../data/Real-Time Sign Language Detection using LSTM.pdf\"  # ← 替換成你的檔名\n",
    "reader = PdfReader(PDF_PATH)\n",
    "\n",
    "pages = []\n",
    "for i, p in enumerate(reader.pages):\n",
    "    try:\n",
    "        pages.append(p.extract_text() or \"\")\n",
    "    except Exception as e:\n",
    "        pages.append(\"\")\n",
    "        \n",
    "raw_text = \"\\n\".join(pages).strip()\n",
    "print(\"Chars:\", len(raw_text))\n",
    "print(raw_text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8c48e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 32\n",
      "Real-Time  Sign  Language  Detection  using  LSTM  \n",
      " Chung-Hao  Tuan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  tuanc@oregonstate.edu  \n",
      "Yun-Hsuan  Chan  School  of  Computer  Science  Oregon  State  University,  Corvallis,  OR  USA  chanyun@oregonstate.edu  \n",
      "Fen\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # 可依文件長短調整（500~1200）\n",
    "    chunk_overlap=120,   # 避免斷句丟資訊\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"，\", \" \"]\n",
    ")\n",
    "chunks = splitter.split_text(raw_text)\n",
    "print(\"Chunks:\", len(chunks))\n",
    "print(chunks[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fac2722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (32, 384) dim: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(embed_model_name)\n",
    "\n",
    "embeddings = embedder.encode(chunks, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "import numpy as np\n",
    "emb = np.array(embeddings).astype(\"float32\")\n",
    "dim = emb.shape[1]\n",
    "print(\"Embedding shape:\", emb.shape, \"dim:\", dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd3f3385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed vectors: 32\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(dim)  # cosine 等效於 inner product + normalized vectors\n",
    "index.add(emb)                  # 加入全部 chunk 向量\n",
    "print(\"Indexed vectors:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "816f44db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunks, embeddings, and index for reuse\n"
     ]
    }
   ],
   "source": [
    "# 建議存檔，方便 Day4 直接讀\n",
    "import json\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "CHUNKS_PATH = f\"{DATA_DIR}/chunks.json\"\n",
    "EMB_PATH    = f\"{DATA_DIR}/embeddings.npy\"\n",
    "INDEX_PATH  = f\"{DATA_DIR}/index.faiss\"\n",
    "\n",
    "with open(CHUNKS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False)\n",
    "\n",
    "np.save(EMB_PATH, emb)\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "\n",
    "print(\"✅ Saved chunks, embeddings, and index for reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39dfe382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded persisted index: 32 vectors\n"
     ]
    }
   ],
   "source": [
    "# ——— 讀取 Day2 成果（若存在）\n",
    "from pathlib import Path\n",
    "have_persist = Path(CHUNKS_PATH).exists() and Path(EMB_PATH).exists() and Path(INDEX_PATH).exists()\n",
    "\n",
    "if have_persist:\n",
    "    import faiss, json\n",
    "    with open(CHUNKS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "    emb = np.load(EMB_PATH).astype(\"float32\")\n",
    "    dim = emb.shape[1]\n",
    "    index = faiss.read_index(INDEX_PATH)\n",
    "    print(\"Loaded persisted index:\", index.ntotal, \"vectors\")\n",
    "else:\n",
    "    print(\"⚠️ 找不到持久化索引；請先執行 Day2 建庫流程（或在本 Notebook 開頭複製 Day2 的建庫 cells）\")\n",
    "\n",
    "# Groq\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "assert GROQ_API_KEY, \"請先在 .env 或環境變數設定 GROQ_API_KEY\"\n",
    "client = Groq(api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11040c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day1_running_llms.ipynb        day3_conversational_rag.ipynb\n",
      "day2_vector_storage.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcb79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'summarize_history_with_groq' from 'src.rag.memory' (/Users/duan/llm-engineer-roadmap/src/rag/memory.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m search_with_meta\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrag_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rag_answer\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationMemory, summarize_history_with_groq\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'summarize_history_with_groq' from 'src.rag.memory' (/Users/duan/llm-engineer-roadmap/src/rag/memory.py)"
     ]
    }
   ],
   "source": [
    "# 基本\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# FAISS + Embedding\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Groq API\n",
    "from groq import Groq\n",
    "\n",
    "# 載入你 Day2 建好的資料 (chunks, emb, index, embedder, client)\n",
    "from src.rag.retriever import search_with_meta\n",
    "from src.rag.rag_pipeline import rag_answer\n",
    "from src.rag.memory import ConversationMemory, summarize_history_with_groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c1c0cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m r1 = \u001b[43mrag_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat methodology does the paper use?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mA1:\u001b[39m\u001b[33m\"\u001b[39m, r1[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSRC1:\u001b[39m\u001b[33m\"\u001b[39m, [s[\u001b[33m\"\u001b[39m\u001b[33midx\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m r1[\u001b[33m\"\u001b[39m\u001b[33msources\u001b[39m\u001b[33m\"\u001b[39m]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-engineer-roadmap/src/rag/rag_pipeline.py:64\u001b[39m, in \u001b[36mrag_chat\u001b[39m\u001b[34m(question, k, summarize_if_over_chars)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history_text) > summarize_if_over_chars:\n\u001b[32m     62\u001b[39m     history_text = summarize_history_with_groq(history_text, client)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m result = \u001b[43mrag_answer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_sources\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m memory.add_turn(question, result[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-engineer-roadmap/src/rag/rag_pipeline.py:22\u001b[39m, in \u001b[36mrag_answer\u001b[39m\u001b[34m(question, k, history_text, temperature, max_tokens, model, return_sources)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrag_answer\u001b[39m(\n\u001b[32m     13\u001b[39m     question,\n\u001b[32m     14\u001b[39m     k=\u001b[32m6\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m ):\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# 檢索（帶 meta）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     hits = \u001b[43msearch_with_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# 編號 + 合併 context\u001b[39;00m\n\u001b[32m     24\u001b[39m     ctx_blocks = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh[\u001b[33m'\u001b[39m\u001b[33midx\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh[\u001b[33m'\u001b[39m\u001b[33mchunk\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hits]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-engineer-roadmap/src/rag/retriever.py:35\u001b[39m, in \u001b[36msearch_with_meta\u001b[39m\u001b[34m(query, k, mmr_lambda, fetch)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_with_meta\u001b[39m(query, k=\u001b[32m5\u001b[39m, mmr_lambda=\u001b[32m0.5\u001b[39m, fetch=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    Day3 版本：回傳包含 idx、score、chunk 的 dict\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     qv = \u001b[43membedder\u001b[49m.encode([query], normalize_embeddings=\u001b[38;5;28;01mTrue\u001b[39;00m).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fetch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m         fetch = \u001b[38;5;28mmax\u001b[39m(k*\u001b[32m4\u001b[39m, \u001b[32m20\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'embedder' is not defined"
     ]
    }
   ],
   "source": [
    "r1 = rag_chat(\"What methodology does the paper use?\")\n",
    "print(\"A1:\", r1[\"answer\"])\n",
    "print(\"SRC1:\", [s[\"idx\"] for s in r1[\"sources\"]])\n",
    "\n",
    "r2 = rag_chat(\"And how does it do Keypoint Extraction specifically?\")\n",
    "print(\"A2:\", r2[\"answer\"])\n",
    "print(\"SRC2:\", [s[\"idx\"] for s in r2[\"sources\"]])\n",
    "\n",
    "r3 = rag_chat(\"Summarize the method in 2 bullet points.\")\n",
    "print(\"A3:\", r3[\"answer\"])\n",
    "print(\"SRC3:\", [s[\"idx\"] for s in r3[\"sources\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
