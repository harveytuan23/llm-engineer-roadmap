{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31328d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pypdf import PdfReader\n",
    "import faiss, numpy as np\n",
    "from groq import Groq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9b540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76d8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀 PDF\n",
    "pdf = PdfReader(\"data/sample.pdf\")\n",
    "raw = \"\\n\".join([p.extract_text() for p in pdf.pages if p.extract_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96cbd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切 chunk\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "chunks = splitter.split_text(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb272fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "emb = embedder.encode(chunks, normalize_embeddings=True)\n",
    "emb = np.array(emb, dtype=\"float32\")\n",
    "dim = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c578992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 index\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9545f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=5):\n",
    "    qv = embedder.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    D, I = index.search(qv, k)\n",
    "    return [chunks[i] for i in I[0]]\n",
    "\n",
    "def rag(question, k=5):\n",
    "    ctx = \"\\n\".join(search(question, k))\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"You are a precise assistant. Answer ONLY using CONTEXT.\"},\n",
    "        {\"role\":\"user\",\"content\":f\"CONTEXT:\\n{ctx}\\n\\nQUESTION: {question}\"}\n",
    "    ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=400\n",
    "    )\n",
    "    return resp.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fa6f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The methodology used in the paper involves the following:\n",
      "\n",
      "1. Data Collection and Preprocessing (Section 3.1), specifically setting up and composing data (Section 3.1.1)\n",
      "2. Using Deep Learning for Sign Language Recognition (Section 2.2), including CNN-based Methods (Section 2.2.1)\n",
      "3. Augmented model with superior generalization capabilities, demonstrated by uniform excellence across all metrics\n"
     ]
    }
   ],
   "source": [
    "print(rag(\"What methodology does the paper use?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd86f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_turns=5):\n",
    "        self.turns = []\n",
    "        self.max_turns = max_turns\n",
    "    def add(self, q, a):\n",
    "        self.turns.append((q,a))\n",
    "        if len(self.turns) > self.max_turns:\n",
    "            self.turns.pop(0)\n",
    "    def text(self):\n",
    "        return \"\\n\".join([f\"User:{q}\\nAI:{a}\" for q,a in self.turns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d033b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "\n",
    "def chat(question):\n",
    "    history = memory.text()\n",
    "    ctx = \"\\n\".join(search(question, 5))\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"You are a precise assistant. Use CONTEXT and HISTORY.\"},\n",
    "        {\"role\":\"user\",\"content\":f\"HISTORY:\\n{history}\\n\\nCONTEXT:\\n{ctx}\\n\\nQUESTION:{question}\"}\n",
    "    ]\n",
    "    resp = client.chat.completions.create(model=\"llama-3.1-8b-instant\",messages=messages,temperature=0.0,max_tokens=400)\n",
    "    answer = resp.choices[0].message.content\n",
    "    memory.add(question, answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740bdb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided CONTEXT, the paper uses the following methodology:\n",
      "\n",
      "1. Data Collection and Preprocessing (Section 3.1)\n",
      "   - Data Setup and Composition (Section 3.1.1)\n",
      "\n",
      "Additionally, it is mentioned that the paper uses the following approaches for Sign Language Recognition:\n",
      "\n",
      "1. Deep Learning (Section 2.2)\n",
      "   - CNN-based Methods (Section 2.2.1)\n",
      "\n",
      "No specific information on Model Architecture (Section 3.5) is provided in the given context.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"What methodology does the paper use?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5151f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided CONTEXT, the results of the paper can be summarized as follows:\n",
      "\n",
      "1. **Effect of Data Augmentation**: The results show that the data augmentation techniques had a substantial impact on model performance. The model trained with augmented data achieved near-perfect accuracy (99.94%) on the validation set, compared to 80.17% for the non-augmented model.\n",
      "\n",
      "2. **Model Stability**: The augmented model demonstrated remarkable stability throughout training, with consistent performance and minimal fluctuations. In contrast, the non-augmented model exhibited pronounced instability throughout training.\n",
      "\n",
      "3. **Generalization Capabilities**: The results indicate that the augmented model has superior generalization capabilities, as demonstrated by its uniform excellence across all metrics.\n",
      "\n",
      "4. **Improved Accuracy**: The data augmentation techniques led to a significant improvement in model performance, with the augmented model achieving:\n",
      "   - 99.94% accuracy on the validation set\n",
      "   - Stability throughout training with consistent performance and minimal fluctuations\n",
      "\n",
      "By using the data augmentation techniques, the model was able to learn and generalize more effectively, leading to improved accuracy and stability.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"And what are the results?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e91ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 23:16:49.587 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.641 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-09-04 23:16:49.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.643 Session state does not function when running a script without `streamlit run`\n",
      "2025-09-04 23:16:49.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-04 23:16:49.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"PDF RAG Chatbot\")\n",
    "question = st.text_input(\"Ask a question:\")\n",
    "if st.button(\"Submit\") and question:\n",
    "    answer = chat(question)\n",
    "    st.write(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b15fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.0.0.177:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "2025-09-04 23:17:12.841 Uncaught app execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 128, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 669, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/duan/llm-engineer-roadmap/quick-demo/app.py\", line 50, in <module>\n",
      "    answer = chat(question)\n",
      "  File \"/Users/duan/llm-engineer-roadmap/quick-demo/app.py\", line 28, in chat\n",
      "    ctx = \"\\n\".join(search(question, 5))  # ← 這裡用 Day2 定義好的 search()\n",
      "                    ^^^^^^\n",
      "NameError: name 'search' is not defined\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 43, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 509, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/duan/llm-engineer-roadmap/.llmvenv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 872, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 550, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
